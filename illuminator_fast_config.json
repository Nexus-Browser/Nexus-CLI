{
  "illuminator_config": {
    "fast_mode": true,
    "use_cloud_fallback": true,
    "preferred_cloud_api": "cohere",
    "local_model_timeout": 10,
    "max_response_length": 512,
    "enable_quantization": true,
    "enable_caching": true,
    "model_path": null,
    "performance": {
      "cpu_threads": 4,
      "memory_limit_gb": 4,
      "inference_batch_size": 1
    },
    "cloud_apis": {
      "cohere": {
        "model": "command-light",
        "max_tokens": 300,
        "temperature": 0.7
      },
      "gemini": {
        "model": "gemini-pro",
        "max_tokens": 300,
        "temperature": 0.7
      },
      "groq": {
        "model": "llama3-8b-8192",
        "max_tokens": 300,
        "temperature": 0.7
      }
    }
  }
}
